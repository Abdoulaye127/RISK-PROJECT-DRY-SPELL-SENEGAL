{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Region  Average Annual Precipitation (mm)  Average Dry Days (<1 mm)  \\\n",
      "0         Dakar                         211.471681                 27.000000   \n",
      "1      Diourbel                         455.699671                 53.004762   \n",
      "2        Fatick                         589.632289                 46.755238   \n",
      "3      Kaffrine                         541.085458                 49.052381   \n",
      "4       Kaolack                         594.642467                 45.379464   \n",
      "5      Kédougou                        1039.506033                 33.698214   \n",
      "6         Kolda                         871.919257                 37.893849   \n",
      "7         Louga                         360.298459                 57.030234   \n",
      "8         Matam                         400.650949                 57.435374   \n",
      "9   Saint-Louis                         287.529878                 64.102092   \n",
      "10      Sédhiou                         931.287531                 34.815476   \n",
      "11  Tambacounda                         701.594068                 44.776014   \n",
      "12        Thiès                         344.149740                 39.839286   \n",
      "13   Ziguinchor                        1172.502285                 30.863095   \n",
      "\n",
      "    Vulnerability  Lack of Coping Capacity  \n",
      "0             0.9                      3.7  \n",
      "1             1.6                      4.3  \n",
      "2             1.4                      5.6  \n",
      "3             1.4                      5.1  \n",
      "4             1.2                      4.6  \n",
      "5             3.1                      6.6  \n",
      "6             1.5                      6.3  \n",
      "7             3.1                      4.6  \n",
      "8             4.3                      5.4  \n",
      "9             1.2                      4.9  \n",
      "10            1.2                      6.0  \n",
      "11            2.2                      6.0  \n",
      "12            1.3                      4.3  \n",
      "13            0.9                      5.5  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "# Charger les fichiers de données\n",
    "chirps_path = '/home/laye/Documents/GUIGMA/CHIRPS/merge_chirps-v2.0_1981_2024_p25_Senegal.nc'\n",
    "shapefile_path = '/home/laye/Documents/GUIGMA/CHIRPS/gadm36_SEN_1.shp'\n",
    "\n",
    "chirps_data = xr.open_dataset(chirps_path)\n",
    "regions = gpd.read_file(shapefile_path)\n",
    "\n",
    "# Indices de vulnérabilité et de capacité d'adaptation\n",
    "vulnerability_cc_data = {\n",
    "    'Region': ['Dakar', 'Diourbel', 'Fatick', 'Kaffrine', 'Kaolack', 'Kédougou', 'Kolda', 'Louga', 'Matam', 'Saint-Louis', 'Sédhiou', 'Tambacounda', 'Thiès', 'Ziguinchor'],\n",
    "    'Vulnerability': [0.9, 1.6, 1.4, 1.4, 1.2, 3.1, 1.5, 3.1, 4.3, 1.2, 1.2, 2.2, 1.3, 0.9],\n",
    "    'Lack of Coping Capacity': [3.7, 4.3, 5.6, 5.1, 4.6, 6.6, 6.3, 4.6, 5.4, 4.9, 6, 6, 4.3, 5.5]\n",
    "}\n",
    "\n",
    "vulnerability_cc_df = pd.DataFrame(vulnerability_cc_data)\n",
    "\n",
    "results = []\n",
    "\n",
    "# Liste des années pour lesquelles nous allons extraire les données \n",
    "years = list(range(1981, 2023))\n",
    "\n",
    "# Itérer sur chaque région\n",
    "for region_name in regions['NAME_1'].unique():\n",
    "    region_shape = regions[regions['NAME_1'] == region_name]\n",
    "    \n",
    "    # Masquer les données CHIRPS en utilisant la région\n",
    "    chirps_region = chirps_data.sel(latitude=slice(region_shape.bounds.miny.values[0], region_shape.bounds.maxy.values[0]), \n",
    "                                    longitude=slice(region_shape.bounds.minx.values[0], region_shape.bounds.maxx.values[0]))\n",
    "    \n",
    "    annual_precipitations = []\n",
    "    dry_days_list = []\n",
    "\n",
    "    for year in years:\n",
    "        # Extraire les données pour l'année spécifiée\n",
    "        chirps_region_year = chirps_region.sel(time=str(year))\n",
    "        \n",
    "        # Calculer la précipitation annuelle moyenne\n",
    "        annual_precipitation = chirps_region_year['precip'].sum(dim='time').mean(dim=['latitude', 'longitude']).values\n",
    "        \n",
    "        # Calculer la précipitation mensuelle\n",
    "        monthly_precipitation = chirps_region_year['precip'].groupby('time.month').sum(dim='time').mean(dim=['latitude', 'longitude'])\n",
    "        \n",
    "        # Identifier les 3 mois les plus pluvieux\n",
    "        top3_rainy_months = monthly_precipitation.sortby(monthly_precipitation, ascending=False).month[:3].values\n",
    "        \n",
    "        # Extraire les données pour les 3 mois les plus pluvieux\n",
    "        rainy_months_data = chirps_region_year.sel(time=chirps_region_year['time.month'].isin(top3_rainy_months))\n",
    "        \n",
    "        # Calculer le nombre de jours sans précipitations (<1 mm)\n",
    "        dry_days = (rainy_months_data['precip'] < 1).sum(dim='time').mean(dim=['latitude', 'longitude']).values\n",
    "        \n",
    "        # Ajouter aux listes\n",
    "        \n",
    "        annual_precipitations.append(annual_precipitation)\n",
    "        dry_days_list.append(dry_days)\n",
    "    \n",
    "    # Calculer la moyenne des précipitations annuelles et des jours secs\n",
    "    average_precipitation = np.mean(annual_precipitations)\n",
    "    average_dry_days = np.mean(dry_days_list)\n",
    "\n",
    "    # Ajouter les résultats à la liste\n",
    "    results.append([region_name, average_precipitation.item(), average_dry_days.item()])\n",
    "\n",
    "# Convertir les résultats en DataFrame\n",
    "hazard_df = pd.DataFrame(results, columns=['Region', 'Average Annual Precipitation (mm)', 'Average Dry Days (<1 mm)'])\n",
    "\n",
    "# Fusionner les données de hazard avec les indices de vulnérabilité et de capacité d'adaptation\n",
    "merged_df = pd.merge(hazard_df, vulnerability_cc_df, left_on='Region', right_on='Region')\n",
    "\n",
    "# Sauvegarder les résultats dans un fichier CSV\n",
    "output_path = '/home/laye/Documents/GUIGMA/dry_spell/RISK_hazard_vulnerability_capacity.csv'\n",
    "merged_df.to_csv(output_path, index=False)\n",
    "\n",
    "# Afficher les résultats\n",
    "print(merged_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Region  Average Annual Precipitation (mm) Rescaled  \\\n",
      "0         Dakar                                   10.000000   \n",
      "1      Diourbel                                   32.871820   \n",
      "2        Fatick                                   45.414538   \n",
      "3      Kaffrine                                   40.868153   \n",
      "4       Kaolack                                   45.883738   \n",
      "5      Kédougou                                   87.544972   \n",
      "6         Kolda                                   71.850561   \n",
      "7         Louga                                   23.937548   \n",
      "8         Matam                                   27.716537   \n",
      "9   Saint-Louis                                   17.122809   \n",
      "10      Sédhiou                                   77.410368   \n",
      "11  Tambacounda                                   55.899698   \n",
      "12        Thiès                                   22.425229   \n",
      "13   Ziguinchor                                  100.000000   \n",
      "\n",
      "    Average Dry Days (<1 mm) Rescaled  Vulnerability Rescaled  \\\n",
      "0                           10.000000               10.000000   \n",
      "1                           73.080770               28.529412   \n",
      "2                           57.921056               23.235294   \n",
      "3                           63.493325               23.235294   \n",
      "4                           54.583787               17.941176   \n",
      "5                           26.248121               68.235294   \n",
      "6                           36.425637               25.882353   \n",
      "7                           82.845517               68.235294   \n",
      "8                           83.828280              100.000000   \n",
      "9                          100.000000               17.941176   \n",
      "10                          28.958307               17.941176   \n",
      "11                          53.119974               44.411765   \n",
      "12                          41.144759               20.588235   \n",
      "13                          19.370862               10.000000   \n",
      "\n",
      "    Lack of Coping Capacity Rescaled  \n",
      "0                          10.000000  \n",
      "1                          28.620690  \n",
      "2                          68.965517  \n",
      "3                          53.448276  \n",
      "4                          37.931034  \n",
      "5                         100.000000  \n",
      "6                          90.689655  \n",
      "7                          37.931034  \n",
      "8                          62.758621  \n",
      "9                          47.241379  \n",
      "10                         81.379310  \n",
      "11                         81.379310  \n",
      "12                         28.620690  \n",
      "13                         65.862069  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "# Charger les fichiers de données\n",
    "chirps_path = '/home/laye/Documents/GUIGMA/CHIRPS/merge_chirps-v2.0_1981_2024_p25_Senegal.nc'\n",
    "shapefile_path = '/home/laye/Documents/GUIGMA/CHIRPS/gadm36_SEN_1.shp'\n",
    "\n",
    "chirps_data = xr.open_dataset(chirps_path)\n",
    "regions = gpd.read_file(shapefile_path)\n",
    "\n",
    "# Indices de vulnérabilité et de capacité d'adaptation\n",
    "vulnerability_cc_data = {\n",
    "    'Region': ['Dakar', 'Diourbel', 'Fatick', 'Kaffrine', 'Kaolack', 'Kédougou', 'Kolda', 'Louga', 'Matam', 'Saint-Louis', 'Sédhiou', 'Tambacounda', 'Thiès', 'Ziguinchor'],\n",
    "    'Vulnerability': [0.9, 1.6, 1.4, 1.4, 1.2, 3.1, 1.5, 3.1, 4.3, 1.2, 1.2, 2.2, 1.3, 0.9],\n",
    "    'Lack of Coping Capacity': [3.7, 4.3, 5.6, 5.1, 4.6, 6.6, 6.3, 4.6, 5.4, 4.9, 6, 6, 4.3, 5.5]\n",
    "}\n",
    "\n",
    "vulnerability_cc_df = pd.DataFrame(vulnerability_cc_data)\n",
    "\n",
    "results = []\n",
    "\n",
    "# Liste des années pour lesquelles nous allons extraire les données \n",
    "years = list(range(1981, 2023))\n",
    "\n",
    "# Fonction pour effectuer le rescaling entre 10 et 100\n",
    "def rescale_to_100(values):\n",
    "    return (values - np.min(values)) / (np.max(values) - np.min(values)) * 90 + 10\n",
    "\n",
    "# Itérer sur chaque région\n",
    "for region_name in regions['NAME_1'].unique():\n",
    "    region_shape = regions[regions['NAME_1'] == region_name]\n",
    "    \n",
    "    # Masquer les données CHIRPS en utilisant la région\n",
    "    chirps_region = chirps_data.sel(latitude=slice(region_shape.bounds.miny.values[0], region_shape.bounds.maxy.values[0]), \n",
    "                                    longitude=slice(region_shape.bounds.minx.values[0], region_shape.bounds.maxx.values[0]))\n",
    "    \n",
    "    annual_precipitations = []\n",
    "    dry_days_list = []\n",
    "\n",
    "    for year in years:\n",
    "        # Extraire les données pour l'année spécifiée\n",
    "        chirps_region_year = chirps_region.sel(time=str(year))\n",
    "        \n",
    "        # Calculer la précipitation annuelle moyenne\n",
    "        annual_precipitation = chirps_region_year['precip'].sum(dim='time').mean(dim=['latitude', 'longitude']).values\n",
    "        \n",
    "        # Calculer la précipitation mensuelle\n",
    "        monthly_precipitation = chirps_region_year['precip'].groupby('time.month').sum(dim='time').mean(dim=['latitude', 'longitude'])\n",
    "        \n",
    "        # Identifier les 3 mois les plus pluvieux\n",
    "        top3_rainy_months = monthly_precipitation.sortby(monthly_precipitation, ascending=False).month[:3].values\n",
    "        \n",
    "        # Extraire les données pour les 3 mois les plus pluvieux\n",
    "        rainy_months_data = chirps_region_year.sel(time=chirps_region_year['time.month'].isin(top3_rainy_months))\n",
    "        \n",
    "        # Calculer le nombre de jours sans précipitations (<1 mm)\n",
    "        dry_days = (rainy_months_data['precip'] < 1).sum(dim='time').mean(dim=['latitude', 'longitude']).values\n",
    "        \n",
    "        # Ajouter aux listes\n",
    "        annual_precipitations.append(annual_precipitation)\n",
    "        dry_days_list.append(dry_days)\n",
    "    \n",
    "    # Calculer la moyenne des précipitations annuelles et des jours secs\n",
    "    average_precipitation = np.mean(annual_precipitations)\n",
    "    average_dry_days = np.mean(dry_days_list)\n",
    "\n",
    "    # Ajouter les résultats à la liste\n",
    "    results.append([region_name, average_precipitation.item(), average_dry_days.item()])\n",
    "\n",
    "# Convertir les résultats en DataFrame\n",
    "hazard_df = pd.DataFrame(results, columns=['Region', 'Average Annual Precipitation (mm)', 'Average Dry Days (<1 mm)'])\n",
    "\n",
    "# Rescaling des 4 variables : Précipitation annuelle, Jours secs, Vulnérabilité, Capacité d'adaptation\n",
    "hazard_df['Average Annual Precipitation (mm) Rescaled'] = rescale_to_100(hazard_df['Average Annual Precipitation (mm)'])\n",
    "hazard_df['Average Dry Days (<1 mm) Rescaled'] = rescale_to_100(hazard_df['Average Dry Days (<1 mm)'])\n",
    "\n",
    "# Fusionner les données de hazard avec les indices de vulnérabilité et de capacité d'adaptation\n",
    "merged_df = pd.merge(hazard_df, vulnerability_cc_df, left_on='Region', right_on='Region')\n",
    "\n",
    "# Rescaling pour 'Vulnerability' et 'Lack of Coping Capacity'\n",
    "merged_df['Vulnerability Rescaled'] = rescale_to_100(merged_df['Vulnerability'])\n",
    "merged_df['Lack of Coping Capacity Rescaled'] = rescale_to_100(merged_df['Lack of Coping Capacity'])\n",
    "\n",
    "# Créer un DataFrame final contenant seulement les variables rééchelonnées\n",
    "final_rescaled_df = merged_df[['Region', \n",
    "                               'Average Annual Precipitation (mm) Rescaled', \n",
    "                               'Average Dry Days (<1 mm) Rescaled', \n",
    "                               'Vulnerability Rescaled', \n",
    "                               'Lack of Coping Capacity Rescaled']]\n",
    "\n",
    "# Sauvegarder les résultats rééchelonnés dans un fichier CSV\n",
    "output_path = '/home/laye/Documents/GUIGMA/dry_spell/RISK_rescaled_variables.csv'\n",
    "final_rescaled_df.to_csv(output_path, index=False)\n",
    "\n",
    "# Afficher les résultats\n",
    "print(final_rescaled_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Region  Average Annual Precipitation (mm) Rescaled\n",
      "0         Dakar                                   10.000000\n",
      "1      Diourbel                                   32.871820\n",
      "2        Fatick                                   45.414538\n",
      "3      Kaffrine                                   40.868153\n",
      "4       Kaolack                                   45.883738\n",
      "5      Kédougou                                   87.544972\n",
      "6         Kolda                                   71.850561\n",
      "7         Louga                                   23.937548\n",
      "8         Matam                                   27.716537\n",
      "9   Saint-Louis                                   17.122809\n",
      "10      Sédhiou                                   77.410368\n",
      "11  Tambacounda                                   55.899698\n",
      "12        Thiès                                   22.425229\n",
      "13   Ziguinchor                                  100.000000\n",
      "         Region  Average Dry Days (<1 mm) Rescaled\n",
      "0         Dakar                          10.000000\n",
      "1      Diourbel                          73.080770\n",
      "2        Fatick                          57.921056\n",
      "3      Kaffrine                          63.493325\n",
      "4       Kaolack                          54.583787\n",
      "5      Kédougou                          26.248121\n",
      "6         Kolda                          36.425637\n",
      "7         Louga                          82.845517\n",
      "8         Matam                          83.828280\n",
      "9   Saint-Louis                         100.000000\n",
      "10      Sédhiou                          28.958307\n",
      "11  Tambacounda                          53.119974\n",
      "12        Thiès                          41.144759\n",
      "13   Ziguinchor                          19.370862\n",
      "         Region  Vulnerability Rescaled\n",
      "0         Dakar               10.000000\n",
      "1      Diourbel               28.529412\n",
      "2        Fatick               23.235294\n",
      "3      Kaffrine               23.235294\n",
      "4       Kaolack               17.941176\n",
      "5      Kédougou               68.235294\n",
      "6         Kolda               25.882353\n",
      "7         Louga               68.235294\n",
      "8         Matam              100.000000\n",
      "9   Saint-Louis               17.941176\n",
      "10      Sédhiou               17.941176\n",
      "11  Tambacounda               44.411765\n",
      "12        Thiès               20.588235\n",
      "13   Ziguinchor               10.000000\n",
      "         Region  Lack of Coping Capacity Rescaled\n",
      "0         Dakar                         10.000000\n",
      "1      Diourbel                         28.620690\n",
      "2        Fatick                         68.965517\n",
      "3      Kaffrine                         53.448276\n",
      "4       Kaolack                         37.931034\n",
      "5      Kédougou                        100.000000\n",
      "6         Kolda                         90.689655\n",
      "7         Louga                         37.931034\n",
      "8         Matam                         62.758621\n",
      "9   Saint-Louis                         47.241379\n",
      "10      Sédhiou                         81.379310\n",
      "11  Tambacounda                         81.379310\n",
      "12        Thiès                         28.620690\n",
      "13   Ziguinchor                         65.862069\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "# Charger les fichiers de données\n",
    "chirps_path = '/home/laye/Documents/GUIGMA/CHIRPS/merge_chirps-v2.0_1981_2024_p25_Senegal.nc'\n",
    "shapefile_path = '/home/laye/Documents/GUIGMA/CHIRPS/gadm36_SEN_1.shp'\n",
    "\n",
    "chirps_data = xr.open_dataset(chirps_path)\n",
    "regions = gpd.read_file(shapefile_path)\n",
    "\n",
    "# Indices de vulnérabilité et de capacité d'adaptation\n",
    "vulnerability_cc_data = {\n",
    "    'Region': ['Dakar', 'Diourbel', 'Fatick', 'Kaffrine', 'Kaolack', 'Kédougou', 'Kolda', 'Louga', 'Matam', 'Saint-Louis', 'Sédhiou', 'Tambacounda', 'Thiès', 'Ziguinchor'],\n",
    "    'Vulnerability': [0.9, 1.6, 1.4, 1.4, 1.2, 3.1, 1.5, 3.1, 4.3, 1.2, 1.2, 2.2, 1.3, 0.9],\n",
    "    'Lack of Coping Capacity': [3.7, 4.3, 5.6, 5.1, 4.6, 6.6, 6.3, 4.6, 5.4, 4.9, 6, 6, 4.3, 5.5]\n",
    "}\n",
    "\n",
    "vulnerability_cc_df = pd.DataFrame(vulnerability_cc_data)\n",
    "\n",
    "results = []\n",
    "\n",
    "# Liste des années pour lesquelles nous allons extraire les données (sans 2023)\n",
    "years = list(range(1981, 2023))\n",
    "\n",
    "# Fonction pour effectuer le rescaling entre 10 et 100\n",
    "def rescale_to_100(values):\n",
    "    return (values - np.min(values)) / (np.max(values) - np.min(values)) * 90 + 10\n",
    "\n",
    "# Itérer sur chaque région\n",
    "for region_name in regions['NAME_1'].unique():\n",
    "    region_shape = regions[regions['NAME_1'] == region_name]\n",
    "    \n",
    "    # Masquer les données CHIRPS en utilisant la région\n",
    "    chirps_region = chirps_data.sel(latitude=slice(region_shape.bounds.miny.values[0], region_shape.bounds.maxy.values[0]), \n",
    "                                    longitude=slice(region_shape.bounds.minx.values[0], region_shape.bounds.maxx.values[0]))\n",
    "    \n",
    "    annual_precipitations = []\n",
    "    dry_days_list = []\n",
    "\n",
    "    for year in years:\n",
    "        # Extraire les données pour l'année spécifiée\n",
    "        chirps_region_year = chirps_region.sel(time=str(year))\n",
    "        \n",
    "        # Calculer la précipitation annuelle totale\n",
    "        annual_precipitation = chirps_region_year['precip'].sum(dim='time').mean(dim=['latitude', 'longitude']).values\n",
    "        \n",
    "        # Calculer la précipitation mensuelle\n",
    "        monthly_precipitation = chirps_region_year['precip'].groupby('time.month').sum(dim='time').mean(dim=['latitude', 'longitude'])\n",
    "        \n",
    "        # Identifier les 3 mois les plus pluvieux\n",
    "        top3_rainy_months = monthly_precipitation.sortby(monthly_precipitation, ascending=False).month[:3].values\n",
    "        \n",
    "        # Extraire les données pour les 3 mois les plus pluvieux\n",
    "        rainy_months_data = chirps_region_year.sel(time=chirps_region_year['time.month'].isin(top3_rainy_months))\n",
    "        \n",
    "        # Calculer le nombre de jours sans précipitations (<1 mm)\n",
    "        dry_days = (rainy_months_data['precip'] < 1).sum(dim='time').mean(dim=['latitude', 'longitude']).values\n",
    "        \n",
    "        # Ajouter aux listes\n",
    "        annual_precipitations.append(annual_precipitation)\n",
    "        dry_days_list.append(dry_days)\n",
    "    \n",
    "    # Calculer la moyenne des précipitations annuelles et des jours secs\n",
    "    average_precipitation = np.mean(annual_precipitations)\n",
    "    average_dry_days = np.mean(dry_days_list)\n",
    "\n",
    "    # Ajouter les résultats à la liste\n",
    "    results.append([region_name, average_precipitation.item(), average_dry_days.item()])\n",
    "\n",
    "# Convertir les résultats en DataFrame\n",
    "hazard_df = pd.DataFrame(results, columns=['Region', 'Average Annual Precipitation (mm)', 'Average Dry Days (<1 mm)'])\n",
    "\n",
    "# Rescaling des variables\n",
    "hazard_df['Average Annual Precipitation (mm) Rescaled'] = rescale_to_100(hazard_df['Average Annual Precipitation (mm)'])\n",
    "hazard_df['Average Dry Days (<1 mm) Rescaled'] = rescale_to_100(hazard_df['Average Dry Days (<1 mm)'])\n",
    "\n",
    "# Fusionner les données de hazard avec les indices de vulnérabilité et de capacité d'adaptation\n",
    "merged_df = pd.merge(hazard_df, vulnerability_cc_df, left_on='Region', right_on='Region')\n",
    "\n",
    "# Rescaling pour 'Vulnerability' et 'Lack of Coping Capacity'\n",
    "merged_df['Vulnerability Rescaled'] = rescale_to_100(merged_df['Vulnerability'])\n",
    "merged_df['Lack of Coping Capacity Rescaled'] = rescale_to_100(merged_df['Lack of Coping Capacity'])\n",
    "\n",
    "# Créer des fichiers CSV séparés pour chaque variable rééchelonnée\n",
    "variables = [\n",
    "    ('Average Annual Precipitation (mm) Rescaled', 'average_annual_precipitation_rescaled.csv'),\n",
    "    ('Average Dry Days (<1 mm) Rescaled', 'average_dry_days_rescaled.csv'),\n",
    "    ('Vulnerability Rescaled', 'vulnerability_rescaled.csv'),\n",
    "    ('Lack of Coping Capacity Rescaled', 'lack_of_coping_capacity_rescaled.csv')\n",
    "]\n",
    "\n",
    "# Sauvegarder chaque variable rééchelonnée dans un fichier CSV\n",
    "for var, filename in variables:\n",
    "    df = merged_df[['Region', var]]\n",
    "    output_path = f'/home/laye/Documents/GUIGMA/dry_spell/{filename}'\n",
    "    df.to_csv(output_path, index=False)\n",
    "\n",
    "# Afficher les résultats\n",
    "for var, _ in variables:\n",
    "    print(merged_df[['Region', var]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RISK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Region           RISK\n",
      "0         Dakar    1000.000000\n",
      "1      Diourbel   43256.810693\n",
      "2        Fatick   82794.238146\n",
      "3      Kaffrine   64802.550791\n",
      "4       Kaolack   34185.451118\n",
      "5      Kédougou  388235.259885\n",
      "6         Kolda  127076.284220\n",
      "7         Louga  138189.848228\n",
      "8         Matam  350019.943593\n",
      "9   Saint-Louis   49634.650994\n",
      "10      Sédhiou   77651.290185\n",
      "11  Tambacounda  197009.384168\n",
      "12        Thiès   18729.291517\n",
      "13   Ziguinchor   39310.059586\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger les données fusionnées avec les variables rééchelonnées\n",
    "merged_df = pd.read_csv('/home/laye/Documents/GUIGMA/dry_spell/RISK_rescaled_variables.csv')\n",
    "\n",
    "# Calculer le HAZARD comme une moyenne des variables rééchelonnées\n",
    "merged_df['HAZARD'] = (merged_df['Average Annual Precipitation (mm) Rescaled'] +\n",
    "                       merged_df['Average Dry Days (<1 mm) Rescaled']) / 2\n",
    "\n",
    "# Calculer le RISK en utilisant la formule : HAZARD * Vulnerability * Lack of Coping Capacity\n",
    "merged_df['RISK'] = (merged_df['HAZARD'] *\n",
    "                     merged_df['Vulnerability Rescaled'] *\n",
    "                     merged_df['Lack of Coping Capacity Rescaled'])\n",
    "\n",
    "# Sauvegarder les résultats dans un fichier CSV\n",
    "risk_output_path = '/home/laye/Documents/GUIGMA/dry_spell/RISK_calculated.csv'\n",
    "merged_df[['Region', 'RISK']].to_csv(risk_output_path, index=False)\n",
    "\n",
    "# Afficher les résultats\n",
    "print(merged_df[['Region', 'RISK']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAP of the four variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les cartes ont été générées et sauvegardées.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "# Charger les données fusionnées avec les variables rééchelonnées\n",
    "df = pd.read_csv('/home/laye/Documents/GUIGMA/dry_spell/RISK_rescaled_variables.csv')\n",
    "\n",
    "# Charger le shapefile des régions du Sénégal\n",
    "shapefile_path = '/home/laye/Documents/GUIGMA/CHIRPS/gadm36_SEN_1.shp'\n",
    "regions = gpd.read_file(shapefile_path)\n",
    "\n",
    "# Fusionner les données avec les informations géographiques\n",
    "regions = regions.merge(df, left_on='NAME_1', right_on='Region')\n",
    "\n",
    "# Définir une fonction pour tracer les cartes\n",
    "def plot_variable(variable, title, output_path):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "    # Normalisation pour avoir la même échelle de couleur pour toutes les variables\n",
    "    norm = Normalize(vmin=df[variable].min(), vmax=df[variable].max())\n",
    "    # Tracer la carte\n",
    "    regions.plot(column=variable, cmap='viridis', linewidth=0.8, ax=ax, edgecolor='0.8', norm=norm, legend=True)\n",
    "    ax.set_title(title, fontdict={'fontsize': '15', 'fontweight' : '3'})\n",
    "    ax.set_axis_off()\n",
    "    # Sauvegarder la carte\n",
    "    plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# Tracer les cartes pour chaque variable\n",
    "plot_variable('Average Annual Precipitation (mm) Rescaled', 'Average Annual Precipitation (mm) Rescaled', '/home/laye/Documents/GUIGMA/dry_spell/Annual_Precipitation_Rescaled.png')\n",
    "plot_variable('Average Dry Days (<1 mm) Rescaled', 'Average Dry Days (<1 mm) Rescaled', '/home/laye/Documents/GUIGMA/dry_spell/Dry_Days_Rescaled.png')\n",
    "plot_variable('Vulnerability Rescaled', 'Vulnerability Rescaled', '/home/laye/Documents/GUIGMA/dry_spell/Vulnerability_Rescaled.png')\n",
    "plot_variable('Lack of Coping Capacity Rescaled', 'Lack of Coping Capacity Rescaled', '/home/laye/Documents/GUIGMA/dry_spell/Coping_Capacity_Rescaled.png')\n",
    "\n",
    "print(\"Les cartes ont été générées et sauvegardées.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les cartes ont été générées et sauvegardées.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "# Charger les données fusionnées avec les variables rééchelonnées\n",
    "df = pd.read_csv('/home/laye/Documents/GUIGMA/dry_spell/RISK_rescaled_variables.csv')\n",
    "\n",
    "# Charger le shapefile des régions du Sénégal\n",
    "shapefile_path = '/home/laye/Documents/GUIGMA/CHIRPS/gadm36_SEN_1.shp'\n",
    "regions = gpd.read_file(shapefile_path)\n",
    "\n",
    "# Fusionner les données avec les informations géographiques\n",
    "regions = regions.merge(df, left_on='NAME_1', right_on='Region')\n",
    "\n",
    "# Définir une fonction pour tracer les cartes avec grille, légende horizontale, et labels\n",
    "def plot_variable(variable, title, output_path):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(12, 12))\n",
    "    \n",
    "    # Normalisation pour avoir une échelle de couleur appropriée\n",
    "    norm = Normalize(vmin=df[variable].min(), vmax=df[variable].max())\n",
    "    \n",
    "    # Tracer la carte\n",
    "    regions.plot(column=variable, cmap='viridis', linewidth=0.8, ax=ax, edgecolor='0.8', norm=norm, legend=True, legend_kwds={'orientation': 'horizontal', 'pad': 0.1, 'shrink': 0.7})\n",
    "    \n",
    "    # Ajouter une grille\n",
    "    ax.grid(True, linestyle='--', linewidth=0.5)\n",
    "    \n",
    "    # Définir les ticks pour les coordonnées\n",
    "    lon_ticks = np.arange(np.floor(regions.total_bounds[0]), np.ceil(regions.total_bounds[2]), 1)\n",
    "    lat_ticks = np.arange(np.floor(regions.total_bounds[1]), np.ceil(regions.total_bounds[3]), 1)\n",
    "    ax.set_xticks(lon_ticks)\n",
    "    ax.set_yticks(lat_ticks)\n",
    "    \n",
    "    # Formater les coordonnées\n",
    "    ax.xaxis.set_major_formatter(ticker.FuncFormatter(lambda x, _: f'{x:.2f}'))\n",
    "    ax.yaxis.set_major_formatter(ticker.FuncFormatter(lambda y, _: f'{y:.2f}'))\n",
    "    \n",
    "    # Ajouter les labels des régions\n",
    "    for idx, row in regions.iterrows():\n",
    "        ax.annotate(text=row['NAME_1'], xy=(row['geometry'].centroid.x, row['geometry'].centroid.y),\n",
    "                    xytext=(3, 3), textcoords=\"offset points\",\n",
    "                    fontsize=8, color='black', ha='center', va='center')\n",
    "    \n",
    "    # Ajouter le titre\n",
    "    ax.set_title(title, fontdict={'fontsize': '15', 'fontweight': '3'})\n",
    "    \n",
    "    # Ajouter les labels pour les coordonnées sur les axes\n",
    "    ax.set_xlabel('Longitude', fontsize=12)\n",
    "    ax.set_ylabel('Latitude', fontsize=12)\n",
    "    \n",
    "    # Ajouter les labels des axes pour tous les côtés\n",
    "    ax.spines['top'].set_visible(True)\n",
    "    ax.spines['right'].set_visible(True)\n",
    "    ax.spines['left'].set_visible(True)\n",
    "    ax.spines['bottom'].set_visible(True)\n",
    "    \n",
    "    # Sauvegarder la carte\n",
    "    plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# Tracer les cartes pour chaque variable\n",
    "plot_variable('Average Annual Precipitation (mm) Rescaled', 'Average Annual Precipitation (mm) Rescaled', '/home/laye/Documents/GUIGMA/dry_spell/Annual_Precipitation_Rescaled.png')\n",
    "plot_variable('Average Dry Days (<1 mm) Rescaled', 'Average Dry Days (<1 mm) Rescaled', '/home/laye/Documents/GUIGMA/dry_spell/Dry_Days_Rescaled.png')\n",
    "plot_variable('Vulnerability Rescaled', 'Vulnerability Rescaled', '/home/laye/Documents/GUIGMA/dry_spell/Vulnerability_Rescaled.png')\n",
    "plot_variable('Lack of Coping Capacity Rescaled', 'Lack of Coping Capacity Rescaled', '/home/laye/Documents/GUIGMA/dry_spell/Coping_Capacity_Rescaled.png')\n",
    "\n",
    "print(\"Les cartes ont été générées et sauvegardées.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les cartes ont été générées et sauvegardées.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "# Charger les données fusionnées avec les variables rééchelonnées\n",
    "df = pd.read_csv('/home/laye/Documents/GUIGMA/dry_spell/RISK_rescaled_variables.csv')\n",
    "\n",
    "# Charger le shapefile des régions du Sénégal\n",
    "shapefile_path = '/home/laye/Documents/GUIGMA/CHIRPS/gadm36_SEN_1.shp'\n",
    "regions = gpd.read_file(shapefile_path)\n",
    "\n",
    "# Fusionner les données avec les informations géographiques\n",
    "regions = regions.merge(df, left_on='NAME_1', right_on='Region')\n",
    "\n",
    "# Définir une fonction pour tracer les cartes avec grille, légende horizontale, et labels\n",
    "def plot_variable(variable, title, output_path):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(12, 12))\n",
    "    \n",
    "    # Normalisation pour avoir une échelle de couleur appropriée\n",
    "    norm = Normalize(vmin=df[variable].min(), vmax=df[variable].max())\n",
    "    \n",
    "    # Tracer la carte avec le colormap 'Reds'\n",
    "    regions.plot(column=variable, cmap='Reds', linewidth=0.8, ax=ax, edgecolor='0.8', norm=norm, legend=True, legend_kwds={'orientation': 'horizontal', 'pad': 0.1, 'shrink': 0.7})\n",
    "    \n",
    "    # Ajouter une grille\n",
    "    ax.grid(True, linestyle='--', linewidth=0.5)\n",
    "    \n",
    "    # Définir les ticks pour les coordonnées\n",
    "    lon_ticks = np.arange(np.floor(regions.total_bounds[0]), np.ceil(regions.total_bounds[2]), 1)\n",
    "    lat_ticks = np.arange(np.floor(regions.total_bounds[1]), np.ceil(regions.total_bounds[3]), 1)\n",
    "    ax.set_xticks(lon_ticks)\n",
    "    ax.set_yticks(lat_ticks)\n",
    "    \n",
    "    # Formater les coordonnées\n",
    "    ax.xaxis.set_major_formatter(ticker.FuncFormatter(lambda x, _: f'{x:.2f}'))\n",
    "    ax.yaxis.set_major_formatter(ticker.FuncFormatter(lambda y, _: f'{y:.2f}'))\n",
    "    \n",
    "    # Ajouter les labels des régions\n",
    "    for idx, row in regions.iterrows():\n",
    "        ax.annotate(text=row['NAME_1'], xy=(row['geometry'].centroid.x, row['geometry'].centroid.y),\n",
    "                    xytext=(3, 3), textcoords=\"offset points\",\n",
    "                    fontsize=8, color='black', ha='center', va='center')\n",
    "    \n",
    "    # Ajouter le titre\n",
    "    ax.set_title(title, fontdict={'fontsize': '15', 'fontweight': '3'})\n",
    "    \n",
    "    # Ajouter les labels pour les coordonnées sur les axes\n",
    "    ax.set_xlabel('Longitude', fontsize=12)\n",
    "    ax.set_ylabel('Latitude', fontsize=12)\n",
    "    \n",
    "    # Ajouter les labels des axes pour tous les côtés\n",
    "    ax.spines['top'].set_visible(True)\n",
    "    ax.spines['right'].set_visible(True)\n",
    "    ax.spines['left'].set_visible(True)\n",
    "    ax.spines['bottom'].set_visible(True)\n",
    "    \n",
    "    # Sauvegarder la carte\n",
    "    plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# Tracer les cartes pour chaque variable\n",
    "plot_variable('Average Annual Precipitation (mm) Rescaled', 'Average Annual Precipitation (mm) Rescaled', '/home/laye/Documents/GUIGMA/dry_spell/Annual_Precipitation_Rescaled.png')\n",
    "plot_variable('Average Dry Days (<1 mm) Rescaled', 'Average Dry Days (<1 mm) Rescaled', '/home/laye/Documents/GUIGMA/dry_spell/Dry_Days_Rescaled.png')\n",
    "plot_variable('Vulnerability Rescaled', 'Vulnerability Rescaled', '/home/laye/Documents/GUIGMA/dry_spell/Vulnerability_Rescaled.png')\n",
    "plot_variable('Lack of Coping Capacity Rescaled', 'Lack of Coping Capacity Rescaled', '/home/laye/Documents/GUIGMA/dry_spell/Coping_Capacity_Rescaled.png')\n",
    "\n",
    "print(\"Les cartes ont été générées et sauvegardées.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RISK MAPPED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La carte du RISK a été générée et sauvegardée.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "# Charger les données fusionnées avec les variables rééchelonnées et le RISK\n",
    "df = pd.read_csv('/home/laye/Documents/GUIGMA/dry_spell/RISK_calculated.csv')\n",
    "\n",
    "# Charger le shapefile des régions du Sénégal\n",
    "shapefile_path = '/home/laye/Documents/GUIGMA/CHIRPS/gadm36_SEN_1.shp'\n",
    "regions = gpd.read_file(shapefile_path)\n",
    "\n",
    "# Fusionner les données avec les informations géographiques\n",
    "regions = regions.merge(df, left_on='NAME_1', right_on='Region')\n",
    "\n",
    "# Définir une fonction pour tracer la carte du RISK\n",
    "def plot_risk():\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "    # Normalisation pour avoir une échelle de couleur appropriée\n",
    "    norm = Normalize(vmin=regions['RISK'].min(), vmax=regions['RISK'].max())\n",
    "    # Tracer la carte\n",
    "    regions.plot(column='RISK', cmap='viridis', linewidth=0.8, ax=ax, edgecolor='0.8', norm=norm, legend=True)\n",
    "    ax.set_title('RISK Map', fontdict={'fontsize': '15', 'fontweight' : '3'})\n",
    "    ax.set_axis_off()\n",
    "    # Sauvegarder la carte\n",
    "    plt.savefig('/home/laye/Documents/GUIGMA/dry_spell/RISK_Map.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# Tracer la carte du RISK\n",
    "plot_risk()\n",
    "\n",
    "print(\"La carte du RISK a été générée et sauvegardée.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La carte du RISK a été générée et sauvegardée.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "# Charger les données fusionnées avec les variables rééchelonnées et le RISK\n",
    "df = pd.read_csv('/home/laye/Documents/GUIGMA/dry_spell/RISK_calculated.csv')\n",
    "\n",
    "# Charger le shapefile des régions du Sénégal\n",
    "shapefile_path = '/home/laye/Documents/GUIGMA/CHIRPS/gadm36_SEN_1.shp'\n",
    "regions = gpd.read_file(shapefile_path)\n",
    "\n",
    "# Fusionner les données avec les informations géographiques\n",
    "regions = regions.merge(df, left_on='NAME_1', right_on='Region')\n",
    "\n",
    "# Définir une fonction pour tracer la carte du RISK\n",
    "def plot_risk():\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(12, 12))\n",
    "    \n",
    "    # Normalisation pour avoir une échelle de couleur appropriée\n",
    "    norm = Normalize(vmin=regions['RISK'].min(), vmax=regions['RISK'].max())\n",
    "    \n",
    "    # Tracer la carte\n",
    "    regions.plot(column='RISK', cmap='viridis', linewidth=0.8, ax=ax, edgecolor='0.8', norm=norm, legend=True, legend_kwds={'orientation': 'horizontal', 'pad': 0.1, 'shrink': 0.7})\n",
    "    \n",
    "    # Ajouter le titre\n",
    "    ax.set_title('RISK Map', fontdict={'fontsize': '15', 'fontweight': '3'})\n",
    "    \n",
    "    # Ajouter les labels pour chaque région\n",
    "    for idx, row in regions.iterrows():\n",
    "        ax.annotate(text=row['NAME_1'], xy=(row['geometry'].centroid.x, row['geometry'].centroid.y),\n",
    "                    xytext=(3, 3), textcoords=\"offset points\",\n",
    "                    fontsize=8, color='black', ha='center', va='center')\n",
    "\n",
    "    # Ajouter les coordonnées latitude et longitude\n",
    "    ax.set_xticks(range(int(regions.total_bounds[0]), int(regions.total_bounds[2]) + 1, 1))\n",
    "    ax.set_yticks(range(int(regions.total_bounds[1]), int(regions.total_bounds[3]) + 1, 1))\n",
    "    ax.xaxis.set_major_formatter(ticker.FuncFormatter(lambda x, _: f'{x:.2f}'))\n",
    "    ax.yaxis.set_major_formatter(ticker.FuncFormatter(lambda y, _: f'{y:.2f}'))\n",
    "    \n",
    "    # Ajouter une grille\n",
    "    ax.grid(True, linestyle='--', linewidth=0.5)\n",
    "    \n",
    "    # Sauvegarder la carte\n",
    "    plt.savefig('/home/laye/Documents/GUIGMA/dry_spell/RISK_Map.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# Tracer la carte du RISK\n",
    "plot_risk()\n",
    "\n",
    "print(\"La carte du RISK a été générée et sauvegardée.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La carte du RISK a été générée et sauvegardée.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "# Charger les données fusionnées avec les variables rééchelonnées et le RISK\n",
    "df = pd.read_csv('/home/laye/Documents/GUIGMA/dry_spell/RISK_calculated.csv')\n",
    "\n",
    "# Charger le shapefile des régions du Sénégal\n",
    "shapefile_path = '/home/laye/Documents/GUIGMA/CHIRPS/gadm36_SEN_1.shp'\n",
    "regions = gpd.read_file(shapefile_path)\n",
    "\n",
    "# Fusionner les données avec les informations géographiques\n",
    "regions = regions.merge(df, left_on='NAME_1', right_on='Region')\n",
    "\n",
    "# Définir une fonction pour tracer la carte du RISK\n",
    "def plot_risk():\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(12, 12))\n",
    "    \n",
    "    # Normalisation pour avoir une échelle de couleur appropriée\n",
    "    norm = Normalize(vmin=regions['RISK'].min(), vmax=regions['RISK'].max())\n",
    "    \n",
    "    # Tracer la carte avec le colormap 'Reds'\n",
    "    regions.plot(column='RISK', cmap='Reds', linewidth=0.8, ax=ax, edgecolor='0.8', norm=norm, legend=True, legend_kwds={'orientation': 'horizontal', 'pad': 0.1, 'shrink': 0.7})\n",
    "    \n",
    "    # Ajouter le titre\n",
    "    ax.set_title('RISK Map', fontdict={'fontsize': '15', 'fontweight': '3'})\n",
    "    \n",
    "    # Ajouter les labels pour chaque région\n",
    "    for idx, row in regions.iterrows():\n",
    "        ax.annotate(text=row['NAME_1'], xy=(row['geometry'].centroid.x, row['geometry'].centroid.y),\n",
    "                    xytext=(3, 3), textcoords=\"offset points\",\n",
    "                    fontsize=8, color='black', ha='center', va='center')\n",
    "    \n",
    "    # Ajouter les coordonnées latitude et longitude\n",
    "    lon_ticks = range(int(regions.total_bounds[0]), int(regions.total_bounds[2]) + 1, 1)\n",
    "    lat_ticks = range(int(regions.total_bounds[1]), int(regions.total_bounds[3]) + 1, 1)\n",
    "    ax.set_xticks(lon_ticks)\n",
    "    ax.set_yticks(lat_ticks)\n",
    "    ax.xaxis.set_major_formatter(ticker.FuncFormatter(lambda x, _: f'{x:.2f}'))\n",
    "    ax.yaxis.set_major_formatter(ticker.FuncFormatter(lambda y, _: f'{y:.2f}'))\n",
    "    \n",
    "    # Ajouter une grille\n",
    "    ax.grid(True, linestyle='--', linewidth=0.5)\n",
    "    \n",
    "    # Sauvegarder la carte\n",
    "    plt.savefig('/home/laye/Documents/GUIGMA/dry_spell/RISK_Map.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# Tracer la carte du RISK\n",
    "plot_risk()\n",
    "\n",
    "print(\"La carte du RISK a été générée et sauvegardée.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
